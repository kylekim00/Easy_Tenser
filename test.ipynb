{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.Weight = nn.Parameter(torch.ones(3))\n",
    "    def forward(self, X,Y,Z):\n",
    "        Y = X * Y\n",
    "        O = Y * Z\n",
    "        return O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "A = 0.0001 * torch.arange(25).reshape(5, 5).float() - 25//2\n",
    "B = 0.0001 * torch.arange(15).reshape(5, 3).float() - 25//2\n",
    "bias = 0.0001 * torch.arange(3).float() - 25//2\n",
    "A.requires_grad = True\n",
    "B.requires_grad = True\n",
    "bias.requires_grad = True\n",
    "C = torch.matmul(A, B) + bias\n",
    "\n",
    "C = torch.relu(C)\n",
    "D = torch.matmul(A, C)\n",
    "Y = torch.Tensor(\n",
    "    [\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 0],\n",
    "    ]\n",
    ")\n",
    "loss = torch.nn.CrossEntropyLoss()(D, Y)\n",
    "C_grad = None\n",
    "def capture_grad(grad):\n",
    "    global C_grad\n",
    "    C_grad = grad\n",
    "D.register_hook(capture_grad)\n",
    "\n",
    "loss.backward()\n",
    "# Attach hook\n",
    "# torch.sum(C).backward()\n",
    "# torch.sum(D).backward()\n",
    "# Gradient of C using PyTorch\n",
    "# grad_C = D.T @ A\n",
    "# print(\"Gradient of C:\\n\", grad_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-42472.8125, -42472.4570, -42472.1055],\n",
       "        [-42471.0430, -42470.6914, -42470.3359],\n",
       "        [-42469.2734, -42468.9219, -42468.5664],\n",
       "        [-42467.5039, -42467.1523, -42466.7930],\n",
       "        [-42465.7305, -42465.3789, -42465.0273]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.Softmax()(D)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0449, -0.1359,  0.0910],\n",
       "        [ 0.0450, -0.1361,  0.0912],\n",
       "        [ 0.0450, -0.1361,  0.0912],\n",
       "        [ 0.0449, -0.1362,  0.0914],\n",
       "        [ 0.0450, -0.1360,  0.0910]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0449, -0.1359,  0.0910],\n",
       "        [ 0.0450, -0.1361,  0.0912],\n",
       "        [ 0.0450, -0.1361,  0.0912],\n",
       "        [ 0.0449, -0.1362,  0.0914],\n",
       "        [ 0.0450, -0.1360,  0.0910]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-12.0000, -11.9999, -11.9998, -11.9997, -11.9996],\n",
       "         [-11.9995, -11.9994, -11.9993, -11.9992, -11.9991],\n",
       "         [-11.9990, -11.9989, -11.9988, -11.9987, -11.9986],\n",
       "         [-11.9985, -11.9984, -11.9983, -11.9982, -11.9981],\n",
       "         [-11.9980, -11.9979, -11.9978, -11.9977, -11.9976]],\n",
       "        requires_grad=True),\n",
       " tensor([[-12.0000, -11.9999, -11.9998],\n",
       "         [-11.9997, -11.9996, -11.9995],\n",
       "         [-11.9994, -11.9993, -11.9992],\n",
       "         [-11.9991, -11.9990, -11.9989],\n",
       "         [-11.9988, -11.9987, -11.9986]], requires_grad=True))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0006, -0.0006, -0.0006, -0.0006, -0.0006],\n",
       "         [-0.0005, -0.0005, -0.0005, -0.0005, -0.0005],\n",
       "         [-0.0005, -0.0005, -0.0005, -0.0005, -0.0005],\n",
       "         [-0.0006, -0.0006, -0.0006, -0.0005, -0.0005],\n",
       "         [-0.0006, -0.0006, -0.0005, -0.0005, -0.0005]]),\n",
       " tensor([[ 161.7550, -489.7880,  328.0330],\n",
       "         [ 161.7536, -489.7839,  328.0303],\n",
       "         [ 161.7523, -489.7798,  328.0276],\n",
       "         [ 161.7509, -489.7758,  328.0249],\n",
       "         [ 161.7496, -489.7717,  328.0221]]),\n",
       " tensor([-13.4807,  40.8191, -27.3384]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.grad, B.grad, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "A = 0.0001 * torch.arange(25).reshape(5, 5).float() - 25//2\n",
    "B = 0.0001 * torch.arange(15).reshape(5, 3).float() - 25//2\n",
    "A.requires_grad = True\n",
    "B.requires_grad = True\n",
    "C = torch.matmul(A, B)\n",
    "\n",
    "C = torch.relu(C)\n",
    "D = torch.matmul(A, C)\n",
    "\n",
    "C_grad = None\n",
    "def capture_grad(grad):\n",
    "    global C_grad\n",
    "    C_grad = grad\n",
    "\n",
    "# Attach hook\n",
    "C.register_hook(capture_grad)\n",
    "# torch.sum(C).backward()\n",
    "torch.sum(D).backward()\n",
    "# Gradient of C using PyTorch\n",
    "# grad_C = D.T @ A\n",
    "# print(\"Gradient of C:\\n\", grad_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([1, 2, 3])\n",
    "Y = torch.Tensor([1, 2, 1])\n",
    "Z = torch.Tensor([2, 4, 6])\n",
    "\n",
    "N = torch.Tensor([3, 5, 7])\n",
    "O = torch.Tensor([4, 6, 8])\n",
    "\n",
    "X.requires_grad = True\n",
    "Y.requires_grad = True\n",
    "Z.requires_grad = True\n",
    "N.requires_grad = True\n",
    "O.requires_grad = True\n",
    "\n",
    "O = X * Y * Z\n",
    "Y = N * O\n",
    "\n",
    "torch.sum(O).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([1., 2., 3.], requires_grad=True) tensor([2., 8., 6.])\n",
      "N tensor([3., 5., 7.], requires_grad=True) None\n",
      "Z tensor([2., 4., 6.], requires_grad=True) tensor([1., 4., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(\"X\",X, X.grad)\n",
    "print(\"N\",N, N.grad)\n",
    "print(\"Z\",Z, Z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5., -2., -1.,  3., -4., -5., -3.,  0., -2.,  0.,  1., -4., -1., -5.,\n",
      "         -1.,  1., -2., -2.]])\n",
      "tensor([[0.0000, 0.0050, 0.0130, 0.6860, 0.0010, 0.0000, 0.0020, 0.0340, 0.0050,\n",
      "         0.0340, 0.0930, 0.0010, 0.0130, 0.0000, 0.0130, 0.0930, 0.0050, 0.0050]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randint(-5, 5, (1, 18)).float()\n",
    "print(a)\n",
    "print(torch.round(torch.nn.Softmax(dim = 1)(a)*1000)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2531931157.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    ef backward(self):\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Operation():\n",
    "    def __init__(self, opcode, upstream, downstream):\n",
    "        self.operation_type = opcode\n",
    "        self.upstream = upstream\n",
    "        self.downstream = downstream\n",
    "\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatAdd(Operation):\n",
    "    def __init__(self, upstream, downstream):\n",
    "        super().__init__(MatAdd, upstream, downstream)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        np.matmul()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3.],[1,2,3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6],\n",
       "       [6, 7],\n",
       "       [8, 4]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[5,6,8]])\n",
    "x2 = np.array([[6, 7, 4]])\n",
    "np.vstack([x1, x2])\n",
    "np.hstack([x1.T,x2.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.75, 2.5 , 3.25, 4.  ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1,21))\n",
    "np.zeros((3, 2))\n",
    "np.arange(1, 4, 2)\n",
    "np.linspace(1, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08187093, 0.8646923 , 0.5605796 , 0.20900085, 0.28125203,\n",
       "        0.98691287, 0.26467386, 0.86587754, 0.30095717, 0.71690376]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1, 10) #0~1사이를 뽑아주는 애"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6730294065870257"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn()   #가우시안 분포로 되어있는 애"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6287497 , -0.77123664, -1.43706051, -0.99526763],\n",
       "       [-1.37702517, -0.45950201, -1.60865558, -0.74902435],\n",
       "       [-1.63286084, -0.28308693, -1.4655558 , -1.22448358]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(3, 4) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[[[1,2],[3,4]]]]).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkh38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
